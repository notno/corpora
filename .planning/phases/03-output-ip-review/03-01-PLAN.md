---
phase: 03-output-ip-review
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/corpora/output/__init__.py
  - src/corpora/output/models.py
  - src/corpora/output/vocab_writer.py
  - src/corpora/models/vocabulary.py
autonomous: true

must_haves:
  truths:
    - "User can generate a .vocab.json file from classified terms"
    - "Output file contains schema version and source metadata"
    - "Output file is pretty-printed JSON for human readability"
  artifacts:
    - path: "src/corpora/output/models.py"
      provides: "VocabularyMetadata, VocabularyEntry, VocabularyOutput models"
      contains: "VOCAB_SCHEMA_VERSION"
    - path: "src/corpora/output/vocab_writer.py"
      provides: "write_vocab_file function for per-document output"
      exports: ["write_vocab_file"]
  key_links:
    - from: "src/corpora/output/vocab_writer.py"
      to: "src/corpora/models/vocabulary.py"
      via: "imports ClassifiedTerm"
      pattern: "from corpora\\.models\\.vocabulary import"
    - from: "src/corpora/output/vocab_writer.py"
      to: "src/corpora/output/models.py"
      via: "uses VocabularyOutput"
      pattern: "VocabularyOutput"
---

<objective>
Create the output foundation for Phase 3: Pydantic models for .vocab.json files and the vocabulary writer that converts classified terms to per-document output.

Purpose: This enables the core OUTPUT-01 requirement - generating one JSON file per source document with full metadata and schema versioning.

Output: `src/corpora/output/` module with models.py and vocab_writer.py
</objective>

<execution_context>
@C:\Users\nrosq\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\nrosq\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-output-ip-review/03-CONTEXT.md
@.planning/phases/03-output-ip-review/03-RESEARCH.md

# Prior work
@src/corpora/models/vocabulary.py
@src/corpora/models/output.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create output module with vocabulary output models</name>
  <files>
    src/corpora/output/__init__.py
    src/corpora/output/models.py
  </files>
  <action>
Create `src/corpora/output/` directory and module.

In `models.py`, implement:

1. `VOCAB_SCHEMA_VERSION = "1.0"` constant for forward compatibility

2. `VocabularyMetadata` model with fields:
   - schema_version: str (defaults to VOCAB_SCHEMA_VERSION)
   - source_path: str (original document path)
   - source_hash: str (MD5 hash for change detection)
   - extracted_at: datetime (default_factory=datetime.now)
   - term_count: int
   - classified_count: int (terms with confidence > 0.3)
   - flagged_count: int (default=0, IP-flagged terms)

3. `VocabularyEntry` model extending ClassifiedTerm fields plus:
   - ip_flag: Optional[str] = None (reason if flagged, e.g., "blocklist:dnd")

4. `VocabularyOutput` model with:
   - metadata: VocabularyMetadata
   - entries: List[VocabularyEntry]
   - to_file(path: Path) method using model_dump_json(indent=2)

Use Pydantic v2 patterns (model_dump_json, Field). Follow existing project style from models/output.py.

In `__init__.py`, export: VOCAB_SCHEMA_VERSION, VocabularyMetadata, VocabularyEntry, VocabularyOutput
  </action>
  <verify>
python -c "from corpora.output import VOCAB_SCHEMA_VERSION, VocabularyOutput; print(f'Schema v{VOCAB_SCHEMA_VERSION}')"
  </verify>
  <done>
VocabularyOutput model can be instantiated and serialized to pretty-printed JSON with schema version
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement vocabulary file writer</name>
  <files>
    src/corpora/output/vocab_writer.py
    src/corpora/output/__init__.py
    src/corpora/models/vocabulary.py
  </files>
  <action>
Create `vocab_writer.py` with:

1. `compute_file_hash(path: Path) -> str` function:
   - Use hashlib.md5 with chunked reading (64KB chunks)
   - Return hexdigest for change detection

2. `write_vocab_file(classified_terms, source_path, output_path, blocklist=None) -> VocabularyOutput`:
   - Accept List[ClassifiedTerm] from Phase 2 output
   - Convert each ClassifiedTerm to VocabularyEntry
   - If blocklist provided, check each term and set ip_flag if matched
   - Create VocabularyMetadata with source_hash from compute_file_hash
   - Build VocabularyOutput and call to_file()
   - Return the VocabularyOutput for further processing

For axes field, use `term.axes.model_dump()` if AxisScores, else use dict directly.

Update ClassifiedTerm in vocabulary.py to add `ip_flag: Optional[str] = None` field for downstream compatibility (IP detection during classification).

Add write_vocab_file and compute_file_hash to output/__init__.py exports.
  </action>
  <verify>
python -c "
from pathlib import Path
from corpora.output import write_vocab_file, compute_file_hash
from corpora.models.vocabulary import ClassifiedTerm, AxisScores
# Test hash function
p = Path('pyproject.toml')
h = compute_file_hash(p)
print(f'Hash: {h[:16]}...')
# Test vocab writer with mock term
term = ClassifiedTerm(
    id='test-fireball', text='Fireball', source='test.pdf',
    intent='offensive', pos='noun', category='spell',
    canonical='fireball', mood='arcane', confidence=0.9
)
output = write_vocab_file([term], p, Path('test_output.vocab.json'))
print(f'Output: {output.metadata.term_count} terms')
Path('test_output.vocab.json').unlink()  # cleanup
"
  </verify>
  <done>
write_vocab_file generates .vocab.json file with metadata, schema version, and entries; compute_file_hash returns MD5 hash
  </done>
</task>

</tasks>

<verification>
Run the output module tests:
```bash
python -c "from corpora.output import *; print('Output module imports OK')"
python -c "from corpora.output.models import VocabularyOutput; v = VocabularyOutput(metadata={'source_path': 'x', 'source_hash': 'abc', 'term_count': 0, 'classified_count': 0}, entries=[]); print(v.model_dump_json(indent=2)[:100])"
```
</verification>

<success_criteria>
- VocabularyOutput model exists with schema_version in metadata
- write_vocab_file converts ClassifiedTerm list to .vocab.json
- Output is pretty-printed JSON (indent=2)
- Source hash computed via MD5 for change detection
- ip_flag field available on VocabularyEntry
</success_criteria>

<output>
After completion, create `.planning/phases/03-output-ip-review/03-01-SUMMARY.md`
</output>
