---
phase: 01-document-parsing
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - src/corpora/parsers/__init__.py
  - src/corpora/parsers/base.py
  - src/corpora/parsers/pdf.py
  - src/corpora/parsers/epub.py
autonomous: true

must_haves:
  truths:
    - "PDF files yield extracted text with page numbers"
    - "EPUB files yield extracted text with chapter numbers"
    - "Extracted text is normalized via normalize_text()"
    - "Font encoding errors produce warnings, not crashes"
  artifacts:
    - path: "src/corpora/parsers/base.py"
      provides: "Abstract parser interface"
      exports: ["BaseParser"]
    - path: "src/corpora/parsers/pdf.py"
      provides: "PDF text extraction"
      exports: ["PDFParser"]
    - path: "src/corpora/parsers/epub.py"
      provides: "EPUB text extraction"
      exports: ["EPUBParser"]
  key_links:
    - from: "src/corpora/parsers/pdf.py"
      to: "src/corpora/utils/normalization.py"
      via: "import normalize_text"
      pattern: "from corpora.utils import normalize_text"
    - from: "src/corpora/parsers/pdf.py"
      to: "src/corpora/models/output.py"
      via: "import DocumentOutput"
      pattern: "from corpora.models import DocumentOutput"
    - from: "src/corpora/parsers/epub.py"
      to: "src/corpora/parsers/base.py"
      via: "extends BaseParser"
      pattern: "class EPUBParser\\(BaseParser\\)"
---

<objective>
Implement PDF and EPUB text extraction using PyMuPDF with a unified parser interface.

Purpose: Enable extraction of clean, normalized text from the two primary document formats. This covers requirements PARSE-01, PARSE-02, PARSE-04, and PARSE-05.

Output: Working PDF and EPUB parsers that produce DocumentOutput with content blocks.
</objective>

<execution_context>
@C:\Users\nrosq\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\nrosq\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/01-document-parsing/01-CONTEXT.md
@.planning/phases/01-document-parsing/01-RESEARCH.md
@.planning/phases/01-document-parsing/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create BaseParser interface and PDFParser</name>
  <files>
    src/corpora/parsers/base.py
    src/corpora/parsers/pdf.py
    src/corpora/parsers/__init__.py
  </files>
  <action>
Create base.py with abstract BaseParser class:
```python
from abc import ABC, abstractmethod
from pathlib import Path
from corpora.models import DocumentOutput

class BaseParser(ABC):
    @abstractmethod
    def can_parse(self, path: Path) -> bool:
        """Check if this parser handles the given file type."""
        pass

    @abstractmethod
    def extract(self, path: Path, flat: bool = False) -> DocumentOutput:
        """Extract text and metadata from document."""
        pass

    @abstractmethod
    def needs_ocr(self, path: Path) -> bool:
        """Determine if OCR is needed for this document."""
        pass
```

Create pdf.py with PDFParser implementation:
- can_parse(): return path.suffix.lower() == ".pdf"
- extract(path, flat=False):
  - Open with pymupdf.open(str(path))
  - Get metadata from doc.metadata
  - Iterate pages with for page_num, page in enumerate(doc)
  - Extract text with page.get_text(sort=True) for proper reading order
  - Apply normalize_text() to each page's text
  - Create ContentBlock for each page with page=page_num+1
  - If flat=True, concatenate all text into single ContentBlock
  - Handle UnicodeDecodeError and font errors with try/except, log warning, continue
  - Return DocumentOutput with format="pdf"
- needs_ocr(path):
  - Open document, check first few pages
  - If page text length < 50 chars AND page has images covering >80% area, return True
  - Use heuristic from RESEARCH.md (check image coverage + minimal text)

Wrap all pymupdf operations in try/except to handle encoding issues gracefully (PARSE-05).
Use warnings.warn() for non-fatal issues, not exceptions.

Export BaseParser and PDFParser from parsers/__init__.py.
  </action>
  <verify>
```bash
python -c "from corpora.parsers import BaseParser, PDFParser; print('Parser imports OK')"
```

If a test PDF is available:
```python
from corpora.parsers import PDFParser
from pathlib import Path
parser = PDFParser()
# Test with any available PDF
# result = parser.extract(Path("test.pdf"))
# print(result.model_dump_json(indent=2)[:500])
print("PDFParser class created successfully")
```
  </verify>
  <done>
BaseParser ABC defined with can_parse, extract, needs_ocr methods. PDFParser extracts text page-by-page using PyMuPDF, applies normalization, handles encoding errors gracefully.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create EPUBParser</name>
  <files>
    src/corpora/parsers/epub.py
    src/corpora/parsers/__init__.py
  </files>
  <action>
Create epub.py with EPUBParser extending BaseParser:
- can_parse(): return path.suffix.lower() == ".epub"
- extract(path, flat=False):
  - Open with pymupdf.open(str(path))
  - Get metadata from doc.metadata
  - Use chapter-aware extraction per RESEARCH.md:
    - Iterate chapters with for chapter_num in range(doc.chapter_count)
    - Get pages per chapter with doc.chapter_page_count(chapter_num)
    - Load pages with doc.load_page((chapter_num, page_num))
    - Extract and normalize text from each page
  - Create ContentBlock for each chapter with chapter=chapter_num+1
  - If flat=True, concatenate all chapters into single ContentBlock
  - Return DocumentOutput with format="epub"
- needs_ocr(): return False (EPUBs are text-based, no OCR needed)

Handle the case where chapter_count might be 0 or 1 (single-chapter EPUBs):
- Fall back to page-by-page extraction if chapter_count == 0

Export EPUBParser from parsers/__init__.py alongside PDFParser and BaseParser.
  </action>
  <verify>
```bash
python -c "from corpora.parsers import EPUBParser; print('EPUBParser import OK')"
python -c "
from corpora.parsers import EPUBParser
parser = EPUBParser()
assert parser.can_parse(__import__('pathlib').Path('test.epub'))
assert not parser.can_parse(__import__('pathlib').Path('test.pdf'))
print('EPUBParser can_parse works')
"
```
  </verify>
  <done>
EPUBParser extracts text chapter-by-chapter using PyMuPDF's location-based addressing. Chapter structure is preserved in output. Fallback to page-by-page for single-chapter EPUBs.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. All parser classes importable: `from corpora.parsers import BaseParser, PDFParser, EPUBParser`
2. PDFParser.can_parse correctly identifies PDF files
3. EPUBParser.can_parse correctly identifies EPUB files
4. Both parsers use normalize_text for text processing
5. Error handling doesn't crash on encoding issues
</verification>

<success_criteria>
- BaseParser ABC defines consistent interface for all parsers
- PDFParser extracts text with page numbers, applies normalization
- EPUBParser extracts text with chapter numbers, applies normalization
- Both parsers produce valid DocumentOutput that serializes to JSON
- Font/encoding errors log warnings but don't crash (PARSE-05)
</success_criteria>

<output>
After completion, create `.planning/phases/01-document-parsing/01-02-SUMMARY.md`
</output>
